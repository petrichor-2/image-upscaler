# ğŸ©» Latent Diffusion for Chest X-Ray Super-Resolution

This project implements a **Latent Diffusion Model (LDM)** pipeline to perform **4Ã— super-resolution** on chest X-ray images. We learn to recover high-resolution (HR) images from noisy latent representations using a **UNet-based denoiser** conditioned on low-resolution (LR) latents and timestep embeddings.

---

## ğŸ“ Dataset

We use the **NIH ChestX-ray14** dataset, containing over 100,000 frontal-view radiographs.  
For training, we preprocess and randomly sample **10,000 paired images**, resizing:
- LR images to **64Ã—64**, then bicubically upsampling to **256Ã—256**
- HR images to **256Ã—256**

Both are passed through a pretrained **VAE encoder (AutoencoderKL from Hugging Face)** to extract:
- LR latent: `4Ã—32Ã—32`  
- HR latent: `4Ã—32Ã—32`  
Then the forward diffusion process begins.

---

## ğŸ§  Model Architecture

Our LDM pipeline consists of three main components:

### 1. ğŸ“¦ Variational Autoencoder (VAE)
- Pretrained AutoencoderKL encodes RGB images to latent space (`3Ã—256Ã—256 â†’ 4Ã—32Ã—32`) and decodes back.
- Used to encode both LR and HR inputs during training, and decode outputs during inference.

### 2. ğŸ”„ Forward Diffusion
- Noise is added to the **HR latent** over `T=300` steps using a **beta schedule** from the DDPM paper.
- Closed-form sampling is used to directly obtain `z_t` from `z_0` and timestep `t`.
- LR latent is **not noised** and is used as a conditional input.
- Timesteps are sampled uniformly and used to condition the model via **sinusoidal embeddings**.

### 3. ğŸ§© UNet Denoiser
- Lightweight encoder-decoder UNet with skip connections.
- Takes as input:  
  `concat([noisy HR latent, clean LR latent]) â†’ [8Ã—32Ã—32]`  
  along with the timestep `t`.
- Predicts the **noise Îµ** added during forward diffusion.
- Trained with **MSE loss** between predicted and true noise.

---

## ğŸš€ Inference (Reverse Diffusion)

- Start from pure noise `z_T âˆ¼ N(0, I)` in HR latent space.
- At each step `t âˆˆ [T, ..., 0]`:
  - Predict noise `ÎµÌ‚_t = UNet(z_t, LR_latent, t)`
  - Use closed-form DDPM reverse update to compute `z_{t-1}`
- After all steps, decode the final latent using the VAE decoder to get a **super-resolved 256Ã—256 image**.

---

## ğŸ“ˆ Evaluation

- Super-resolved images are compared to ground-truth HR images.
- **Peak Signal-to-Noise Ratio (PSNR)** and **Structural Similarity Index (SSIM)** are used as evaluation metrics.
- Our model significantly outperforms bicubic interpolation on both metrics.

---

## âš¡ Edge Deployment with TensorRT

To optimize for fast deployment on NVIDIA GPUs:

- âœ… Exported the trained UNet model to **ONNX** format (`.onnx`)
- âœ… Converted ONNX to a **TensorRT engine** (`.trt`) for runtime execution
- âœ… Implemented CUDA-based inference pipeline using **PyCUDA + TensorRT**
- âœ… Achieved **~3.8Ã— faster inference** with negligible quality loss (lower precision enabled by TRT)
- âœ… Integrated into main inference pipeline with seamless fallback between PyTorch and TensorRT

---

## âœ… Project Status

- âœ… VAE integration for image â†” latent mapping  
- âœ… Forward diffusion process (closed-form)  
- âœ… Custom UNet with LR + timestep conditioning  
- âœ… Training loop (PyTorch)  
- âœ… Reverse diffusion and inference sampling  
- âœ… Evaluation (PSNR, SSIM)  
- âœ… ONNX export and TensorRT deployment  
- âœ… End-to-end super-resolution working on GPU  
- âœ… Modular PyTorch & TensorRT inference wrappers

---

## ğŸ› ï¸ Dependencies

- Python 3.8+
- PyTorch â‰¥ 1.13  
- Hugging Face Transformers / Diffusers (AutoencoderKL)
- NumPy
- TensorRT 8.x / 10.x
- PyCUDA

---

## ğŸ“š References

- **Denoising Diffusion Probabilistic Models**  
  [https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2006.11239)
- **U-Net: Biomedical Image Segmentation**  
  [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)
- **High-Resolution Image Synthesis with Latent Diffusion Models**  
  [https://arxiv.org/abs/2112.10752](https://arxiv.org/abs/2112.10752)
