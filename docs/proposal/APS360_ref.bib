@article{Sabina23,
  author = {Umirzakova, Sabina and Mardieva, Sevara and Muksimova, Shakhnoza and Ahmad, Shabir and Whangbo, Taegkeun},
  title = {Enhancing the Super-Resolution of Medical Images: Introducing the Deep Residual Feature Distillation Channel Attention Network for Optimized Performance and Efficiency},
  journal = {Bioengineering},
  volume = {10},
  number = {11},
  pages = {1332},
  year = {2023},
  address = {Basel, Switzerland},
  doi = {10.3390/bioengineering10111332}
}

@book{cover2012elements,
  title={Elements of Information Theory},
  author={Cover, T.M. and Thomas, J.A.},
  isbn={9781118585771},
  lccn={2005047799},
  url={https://books.google.ca/books?id=VWq5GG6ycxMC},
  year={2012},
  publisher={Wiley}
}

@article{wang2004image,
  author = {Wang, Zhou and Bovik, Alan and Sheikh, Hamid and Member, Student and Simoncelli, Eero},
  year = {2003},
  month = {11},
  pages = {},
  title = {Image Quality Assessment: From Error Measurement to Structural Similarity},
  volume = {13},
  journal = {IEEE Trans. Imgage Process.}
}

@article{huynh2008scope,
  author = {Q. Huynh-Thu  and M. Ghanbari },
  title = {Scope of validity of PSNR in image/video quality assessment},
  journal = {Electronics Letters},
  volume = {44},
  issue = {13},
  pages = {800-801},
  year = {2008},
  doi = {10.1049/el:20080522},
  URL = {https://digital-library.theiet.org/doi/abs/10.1049/el%3A20080522},
  eprint = {https://digital-library.theiet.org/doi/pdf/10.1049/el%3A20080522},
  abstract = { Experimental data are presented that clearly demonstrate the scope of application of peak signal-to-noise ratio (PSNR) as a video quality metric. It is shown that as long as the video content and the codec type are not changed, PSNR is a valid quality measure. However, when the content is changed, correlation between subjective quality and PSNR is highly reduced. Hence PSNR cannot be a reliable method for assessing the video quality across different video contents. }
}

@article{dong2015cnn,
  author       = {Chao Dong and Chen Change Loy and Kaiming He and Xiaoou Tang},
  title        = {Image Super-Resolution Using Deep Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/1501.00092},
  year         = {2015},
  url          = {http://arxiv.org/abs/1501.00092},
  eprinttype    = {arXiv},
  eprint       = {1501.00092},
  timestamp    = {Wed, 18 Sep 2024 14:53:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DongLHT15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{ledig2017gan,
  author={Ledig, Christian and Theis, Lucas and Huszár, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}, 
  year={2017},
  volume={},
  number={},
  pages={105-114},
  keywords={Image resolution;Signal resolution;Gallium nitride;Image reconstruction;Manifolds;Training;Network architecture},
  doi={10.1109/CVPR.2017.19}
}

@InProceedings{wang2018esrgan,
  author="Wang, Xintao
  and Yu, Ke
  and Wu, Shixiang
  and Gu, Jinjin
  and Liu, Yihao
  and Dong, Chao
  and Qiao, Yu
  and Loy, Chen Change",
  editor="Leal-Taix{\'e}, Laura and Roth, Stefan",
  title="ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks",
  booktitle="Computer Vision -- ECCV 2018 Workshops",
  year="2019",
  publisher="Springer International Publishing",
  address="Cham",
  pages="63--79",
  abstract="The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN -- network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge (region 3) with the best perceptual index. The code is available at https://github.com/xinntao/ESRGAN.",
  isbn="978-3-030-11021-5"
}

@misc{rombach2022latent,
  title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
  author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
  year={2022},
  eprint={2112.10752},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2112.10752}, 
}

@misc{mehdi2025edgesd,
  title={Edge-SD-SR: Low Latency and Parameter Efficient On-device Super-Resolution with Stable Diffusion via Bidirectional Conditioning}, 
  author={Mehdi Noroozi and Isma Hadji and Victor Escorcia and Anestis Zaganidis and Brais Martinez and Georgios Tzimiropoulos},
  year={2025},
  eprint={2412.06978},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2412.06978}, 
}

@InProceedings{ronneberger2015unet,
  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series       = "LNCS",
  volume       = "9351",
  pages        = "234--241",
  year         = "2015",
  publisher    = "Springer",
  note         = "(available on arXiv:1505.04597 [cs.CV])",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a"
}

@article{Galanty2024BEAMRAD,
  author = {Galanty, M. and Luitse, D. and Noteboom, S.H. and Noteboom, S.H. and van Ooijen, P.M.A. and Homan, M. and Nagtegaal, M. and van der Laak, J.A.W.M. and Huisman, H.},
  title = {Assessing the documentation of publicly available medical image and signal datasets and their impact on bias using the BEAMRAD tool},
  journal = {Scientific Reports},
  volume = {14},
  pages = {31846},
  year = {2024},
  publisher = {Nature Publishing Group},
  doi = {10.1038/s41598-024-83218-5},
  url = {https://doi.org/10.1038/s41598-024-83218-5}
}

@article{Shin2024SuperResolution,
  author = {Shin, Minji and Seo, Mohan and Lee, Kyung and Yoon, Kyuri},
  title = {Super-resolution techniques for biomedical applications and challenges},
  journal = {Biomedical Engineering Letters},
  volume = {14},
  number = {3},
  pages = {465--496},
  year = {2024},
  month = mar,
  doi = {10.1007/s13534-024-00365-4},
  pmid = {38645589},
  pmcid = {PMC11026337}
}

@misc{olatunji2019caveats,
  title={Caveats in Generating Medical Imaging Labels from Radiology Reports},
  author={Tobi Olatunji and Li Yao and Ben Covington and Alexander Rhodes and Anthony Upton},
  year={2019},
  eprint={1905.02283},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  note={Accepted workshop contribution for Medical Imaging with Deep Learning (MIDL), 2019},
  url={https://doi.org/10.48550/arXiv.1905.02283}
}