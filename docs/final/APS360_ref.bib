@article{Sabina23,
  author = {Umirzakova, Sabina and Mardieva, Sevara and Muksimova, Shakhnoza and Ahmad, Shabir and Whangbo, Taegkeun},
  title = {Enhancing the Super-Resolution of Medical Images: Introducing the Deep Residual Feature Distillation Channel Attention Network for Optimized Performance and Efficiency},
  journal = {Bioengineering},
  volume = {10},
  number = {11},
  pages = {1332},
  year = {2023},
  address = {Basel, Switzerland},
  doi = {10.3390/bioengineering10111332}
}

@INPROCEEDINGS{wang17,
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases}, 
  year={2017},
  volume={},
  number={},
  pages={3462-3471},
  keywords={Diseases;X-ray imaging;Pathology;Databases;Biomedical imaging;Machine learning;Image segmentation},
  doi={10.1109/CVPR.2017.369}}

@article{demner2016,
  title={Preparing a collection of radiology examinations for distribution and retrieval},
  author={Demner-Fushman, Dina and Kohli, Marc D. and Rosenman, Martin B. and Shooshan, Sarah E. and Rodriguez, Laritza and Antani, Sameer and Thoma, George R. and McDonald, Clement J.},
  journal={Journal of the American Medical Informatics Association: JAMIA},
  volume={23},
  number={2},
  pages={304--310},
  year={2016},
  month={March},
  doi={10.1093/jamia/ocv080},
  pmid={26133894},
  pmcid={PMC5009925},
  publisher={Oxford University Press}
}

@online{datacamp2023,
  author    = {DataCamp},
  title     = {A Complete Guide to Data Augmentation in Machine Learning},
  year      = {2023},
  url       = {https://www.datacamp.com/tutorial/complete-guide-data-augmentation},
  note      = {Accessed: 2025-07-12},
  organization = {DataCamp}
}

@article {athalye23,
	Title = {Domain-guided data augmentation for deep learning on medical imaging},
	Author = {Athalye, Chinmayee and Arnaout, Rima},
	DOI = {10.1371/journal.pone.0282532},
	Number = {3},
	Volume = {18},
	Year = {2023},
	Journal = {PloS one},
	ISSN = {1932-6203},
	Pages = {e0282532},
	URL = {https://europepmc.org/articles/PMC10035842},
}

@article{sanaat22,
  title={Robust-Deep: A method for increasing brain imaging datasets to improve deep learning models’ performance and robustness},
  author={Sanaat, Amir and Shiri, Iraj and Ferdowsi, Somayeh and others},
  journal={Journal of Digital Imaging},
  volume={35},
  number={2},
  pages={469--481},
  year={2022},
  publisher={Springer},
  doi={10.1007/s10278-021-00536-0},
  url={https://doi.org/10.1007/s10278-021-00536-0}
}

@InProceedings{ronneberger2015unet,
  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series       = "LNCS",
  volume       = "9351",
  pages        = "234--241",
  year         = "2015",
  publisher    = "Springer",
  note         = "(available on arXiv:1505.04597 [cs.CV])",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a"
}

@inproceedings{ho20,
author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
title = {Denoising diffusion probabilistic models},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {574},
numpages = {12},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@book{cover2012elements,
  title={Elements of Information Theory},
  author={Cover, T.M. and Thomas, J.A.},
  isbn={9781118585771},
  lccn={2005047799},
  url={https://books.google.ca/books?id=VWq5GG6ycxMC},
  year={2012},
  publisher={Wiley}
}

@article{wang2004image,
author = {Wang, Zhou and Bovik, Alan and Sheikh, Hamid and Member, Student and Simoncelli, Eero},
year = {2003},
month = {11},
pages = {},
title = {Image Quality Assessment: From Error Measurement to Structural Similarity},
volume = {13},
journal = {IEEE Trans. Image Process.}
}

@article{huynh2008scope,
author = {Q. Huynh-Thu  and M. Ghanbari },
title = {Scope of validity of PSNR in image/video quality assessment},
journal = {Electronics Letters},
volume = {44},
issue = {13},
pages = {800-801},
year = {2008},
doi = {10.1049/el:20080522},

URL = {https://digital-library.theiet.org/doi/abs/10.1049/el%3A20080522},
eprint = {https://digital-library.theiet.org/doi/pdf/10.1049/el%3A20080522}
,
    abstract = { Experimental data are presented that clearly demonstrate the scope of application of peak signal-to-noise ratio (PSNR) as a video quality metric. It is shown that as long as the video content and the codec type are not changed, PSNR is a valid quality measure. However, when the content is changed, correlation between subjective quality and PSNR is highly reduced. Hence PSNR cannot be a reliable method for assessing the video quality across different video contents. }
}

@article{dong2015cnn,
  author       = {Chao Dong and
                  Chen Change Loy and
                  Kaiming He and
                  Xiaoou Tang},
  title        = {Image Super-Resolution Using Deep Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/1501.00092},
  year         = {2015},
  url          = {http://arxiv.org/abs/1501.00092},
  eprinttype    = {arXiv},
  eprint       = {1501.00092},
  timestamp    = {Wed, 18 Sep 2024 14:53:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/DongLHT15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{ledig2017gan,

  author={Ledig, Christian and Theis, Lucas and Huszár, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},

  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 

  title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network}, 

  year={2017},

  volume={},

  number={},

  pages={105-114},

  keywords={Image resolution;Signal resolution;Gallium nitride;Image reconstruction;Manifolds;Training;Network architecture},

  doi={10.1109/CVPR.2017.19}
}

@InProceedings{wang2018esrgan,
author="Wang, Xintao
and Yu, Ke
and Wu, Shixiang
and Gu, Jinjin
and Liu, Yihao
and Dong, Chao
and Qiao, Yu
and Loy, Chen Change",
editor="Leal-Taix{\'e}, Laura
and Roth, Stefan",
title="ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks",
booktitle="Computer Vision -- ECCV 2018 Workshops",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="63--79",
abstract="The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN -- network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge (region 3) with the best perceptual index. The code is available at https://github.com/xinntao/ESRGAN.",
isbn="978-3-030-11021-5"
}

@misc{rombach2022latent,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}

@misc{mehdi2025edgesd,
      title={Edge-SD-SR: Low Latency and Parameter Efficient On-device Super-Resolution with Stable Diffusion via Bidirectional Conditioning}, 
      author={Mehdi Noroozi and Isma Hadji and Victor Escorcia and Anestis Zaganidis and Brais Martinez and Georgios Tzimiropoulos},
      year={2025},
      eprint={2412.06978},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.06978}, 
}

@article{Galanty2024BEAMRAD,
author = {Galanty, M. and Luitse, D. and Noteboom, S.H. and Noteboom, S.H. and van Ooijen, P.M.A. and Homan, M. and Nagtegaal, M. and van der Laak, J.A.W.M. and Huisman, H.},
title = {Assessing the documentation of publicly available medical image and signal datasets and their impact on bias using the BEAMRAD tool},
journal = {Scientific Reports},
volume = {14},
pages = {31846},
year = {2024},
publisher = {Nature Publishing Group},
doi = {10.1038/s41598-024-83218-5},
url = {https://doi.org/10.1038/s41598-024-83218-5}
}

@article{Shin2024SuperResolution,
author = {Shin, Minji and Seo, Mohan and Lee, Kyung and Yoon, Kyuri},
title = {Super-resolution techniques for biomedical applications and challenges},
journal = {Biomedical Engineering Letters},
volume = {14},
number = {3},
pages = {465--496},
year = {2024},
month = mar,
doi = {10.1007/s13534-024-00365-4},
pmid = {38645589},
pmcid = {PMC11026337}
}

@misc{olatunji2019caveats,
title={Caveats in Generating Medical Imaging Labels from Radiology Reports},
author={Tobi Olatunji and Li Yao and Ben Covington and Alexander Rhodes and Anthony Upton},
year={2019},
eprint={1905.02283},
archivePrefix={arXiv},
primaryClass={cs.CL},
note={Accepted workshop contribution for Medical Imaging with Deep Learning (MIDL), 2019},
url={https://doi.org/10.48550/arXiv.1905.02283}
}

@InProceedings{zhang2018lpips,
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},
title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
} 

@ARTICLE{keys1981cubic,
  author={Keys, R.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Cubic convolution interpolation for digital image processing}, 
  year={1981},
  volume={29},
  number={6},
  pages={1153-1160},
  keywords={Convolution;Interpolation;Digital images;Kernel;Image sampling;Sampling methods;Signal processing algorithms;Image processing;Image converters;Boundary conditions},
  doi={10.1109/TASSP.1981.1163711}}
}